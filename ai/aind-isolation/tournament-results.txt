

(aind) C:\Users\Owner\Documents\Udacity\ai\AIND-Isolation>python tournament.py

This script evaluates the performance of the custom_score evaluation
function against a baseline agent using alpha-beta search and iterative
deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use
ID and alpha-beta search with the custom_score functions defined in
game_agent.py.

                        *************************
                             Playing Matches
                        *************************

 Match #   Opponent    AB_Improved   AB_Custom   AB_Custom_2  AB_Custom_3
                        Won | Lost   Won | Lost   Won | Lost   Won | Lost
    1       Random       9  |   1    10  |   0    10  |   0    10  |   0
    2       MM_Open      7  |   3     8  |   2     7  |   3     7  |   3
    3      MM_Center     8  |   2     9  |   1     9  |   1     8  |   2
    4     MM_Improved    3  |   7     9  |   1     8  |   2     6  |   4
    5       AB_Open      4  |   6     4  |   6     4  |   6     5  |   5
    6      AB_Center     7  |   3     6  |   4     4  |   6     5  |   5
    7     AB_Improved    4  |   6     6  |   4     6  |   4     5  |   5
--------------------------------------------------------------------------
           Win Rate:      60.0%        74.3%        68.6%        65.7%

(aind) C:\Users\Owner\Documents\Udacity\ai\AIND-Isolation>python tournament.py

This script evaluates the performance of the custom_score evaluation
function against a baseline agent using alpha-beta search and iterative
deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use
ID and alpha-beta search with the custom_score functions defined in
game_agent.py.

                        *************************
                             Playing Matches
                        *************************

 Match #   Opponent    AB_Improved   AB_Custom   AB_Custom_2  AB_Custom_3
                        Won | Lost   Won | Lost   Won | Lost   Won | Lost
    1       Random      10  |   0     9  |   1     9  |   1    10  |   0
    2       MM_Open      8  |   2     8  |   2     6  |   4     6  |   4
    3      MM_Center     9  |   1     9  |   1    10  |   0     7  |   3
    4     MM_Improved    7  |   3     7  |   3     5  |   5     6  |   4
    5       AB_Open      6  |   4     7  |   3     5  |   5     4  |   6
    6      AB_Center     6  |   4     6  |   4     4  |   6     4  |   6
    7     AB_Improved    3  |   7     6  |   4     5  |   5     6  |   4
--------------------------------------------------------------------------
           Win Rate:      70.0%        74.3%        62.9%        61.4%

(aind) C:\Users\Owner\Documents\Udacity\ai\AIND-Isolation>python tournament.py

This script evaluates the performance of the custom_score evaluation
function against a baseline agent using alpha-beta search and iterative
deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use
ID and alpha-beta search with the custom_score functions defined in
game_agent.py.

                        *************************
                             Playing Matches
                        *************************

 Match #   Opponent    AB_Improved   AB_Custom   AB_Custom_2  AB_Custom_3
                        Won | Lost   Won | Lost   Won | Lost   Won | Lost
    1       Random       9  |   1    10  |   0    10  |   0     9  |   1
    2       MM_Open      6  |   4     7  |   3     9  |   1     8  |   2
    3      MM_Center     9  |   1     9  |   1    10  |   0     8  |   2
    4     MM_Improved    6  |   4     8  |   2     4  |   6     6  |   4
    5       AB_Open      4  |   6     7  |   3     4  |   6     5  |   5
    6      AB_Center     6  |   4     6  |   4     6  |   4     5  |   5
    7     AB_Improved    6  |   4     7  |   3     8  |   2     4  |   6
--------------------------------------------------------------------------
           Win Rate:      65.7%        77.1%        72.9%        64.3%

(aind) C:\Users\Owner\Documents\Udacity\ai\AIND-Isolation>